<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Brian B. Avants (PENN) and Nicholas J. Tustison (UVA)" />
  <title>A Brief History of Advanced Normalization Tools (ANTs)</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/reveal.min.css"/>

  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }

  </style>

    <style type="text/css">code{white-space: pre;}</style>


<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #303030; color: #cccccc; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; }
td.sourceCode { padding-left: 5px; }
pre, code { color: #cccccc; background-color: #303030; }
code > span.kw { color: #f0dfaf; }
code > span.dt { color: #dfdfbf; }
code > span.dv { color: #dcdccc; }
code > span.bn { color: #dca3a3; }
code > span.fl { color: #c0bed1; }
code > span.ch { color: #dca3a3; }
code > span.st { color: #cc9393; }
code > span.co { color: #7f9f7f; }
code > span.ot { color: #efef8f; }
code > span.al { color: #ffcfaf; }
code > span.fu { color: #efef8f; }
code > span.er { color: #c3bf9f; }
</style>

<link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/theme/night.css" id="theme">

<style type="text/css">
.reveal section img {
  background: rgba(255, 255, 255, 0.85);
}
</style>

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'index_files/reveal.js-2.6.1/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>
    <!--[if lt IE 9]>
    <script src="index_files/reveal.js-2.6.1/lib/js/html5shiv.js"></script>
    <![endif]-->

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title"><span style="color:red;">A Brief History of Advanced Normalization Tools (<em>ANTs</em>)</span></h1>
    <h2 class="author">Brian B. Avants (<span style="color:blue;">PENN</span>) and <br />Nicholas J. Tustison (<span style="color:orange;">UVA</span>)</h2>
    <h3 class="date"></h3>
</section>

<section id="section" class="slide level2">
<h1></h1>
<div align="center">
<img src="figures/ireland.png" frameborder="0"></img>
</div>
<p>This talk is online at <a href="http://stnava.github.io/ANTsTalk/#/"><a href="http://stnava.github.io/ANTsTalk/" class="uri">http://stnava.github.io/ANTsTalk/</a></a> with colored <a href="http://stnava.github.io/ANTsTalk/#/">links</a> meant to be clicked for more information</p>
</section>
<section><section id="background" class="titleslide slide level1"><h1>Background</h1></section><section id="image-mapping-perception-1878" class="slide level2">
<h1>Image mapping &amp; perception: 1878</h1>
<p><img src="figures/galton.png" /></p>
<ul>
<li class="fragment"><p>Francis Galton: Can we see criminality in the face?</p></li>
<li class="fragment"><p>(maybe he should have used ANTs?)</p></li>
</ul>
</section><section id="founding-developers" class="slide level2">
<h1>Founding developers</h1>
<div align="center">
<img width="1433" src="./figures/bant2.png" frameborder="0"></img>
</div>
</section><section id="long-term-collaborators" class="slide level2">
<h1>Long-term collaborators</h1>
<p><img src="figures/antscollab.jpg" /></p>
<p><span class="math">\(+\)</span> <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p>
</section><section id="general-purpose-library-for-multivariate-image-registration-segmentation-statistical-analysis-tools" class="slide level2">
<h1>General purpose library for multivariate image registration, segmentation &amp; statistical analysis tools</h1>
<ul>
<li class="fragment"><p>170,000+ lines of C++, 6<span class="math">\(+\)</span> years of work, 15+ collaborators.</p></li>
<li class="fragment"><p>Generic mathematical methods that are tunable for application specific domains: no-free lunch</p></li>
<li class="fragment"><p>Deep testing on multiple platforms … osx, linux, windows.</p></li>
<li class="fragment"><p>Several “wins” in public knock-abouts ( <a href="http://www.ncbi.nlm.nih.gov/pubmed/19195496">Klein 2009</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/21632295">Murphy 2011</a>, <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3837555/">SATA 2012 and 2013</a>, <a href="http://martinos.org/qtim/miccai2013/proc_brats_2013.pdf">BRATS 2013</a>, others )</p></li>
</ul>
<pre><code>    An algorithm must use prior knowledge about a problem 
    to do well on that problem </code></pre>
</section></section>
<section><section id="ants-optimizes-mathematically-well-defined-objective-functions-guided-by-prior-knowledge" class="titleslide slide level1"><h1><em>ANTs</em> optimizes mathematically well-defined <span style="color:red;">objective functions</span> guided by <span style="color:red;">prior knowledge</span> …</h1></section></section>
<section><section id="including-that-of-developers-domain-experts-and-other-colleagues" class="titleslide slide level1"><h1>… including that of developers, domain experts and other colleagues …</h1></section></section>
<section><section id="plug-your-ideas-into-our-software-to-gain-insight-into-biomedical-data" class="titleslide slide level1"><h1>plug <em>your ideas</em> into our software to gain insight into biomedical data …</h1></section></section>
<section><section id="our-strong-mathematical-and-software-engineering-foundation-leads-to-near-limitless-opportunities-for-innovation-in-a-variety-of-application-domains" class="titleslide slide level1"><h1>our strong <span style="color:red;">mathematical and software engineering</span> foundation leads to near limitless opportunities for innovation in a variety of application domains</h1></section><section id="ants-is-open-to-different-image-types-multiple-modalities-anatomical-regions-segmentation-priors-etc." class="slide level2">
<h1>ANTs is <em>open</em> to different image types, multiple modalities, anatomical regions, segmentation priors, etc.</h1>
</section><section id="ants-neuroscience" class="slide level2">
<h1>ANTs &amp; Neuroscience</h1>
<p>We need statistical image analysis <br />at several scales in modern neuroscience</p>
<ul>
<li class="fragment"><p>Macro: <em>in vivo</em> structural and functional MRI</p></li>
<li class="fragment"><p>Micro: high-resolution post-mortem MRI links with in vivo MRI</p></li>
<li class="fragment"><p>Nano: neuron reconstruction …</p></li>
<li class="fragment"><p>Solutions that are consistent across these scales have the potential to build multi-scale feature sets or templates and provide new insights into brain structure and function</p></li>
<li class="fragment"><p>E.g. Parcellation constraints based on histology, tractography, function …</p></li>
<li class="fragment"><p>Statistical definitions of anatomy/pathology?</p></li>
<li class="fragment"><p>Reinvention of these solutions within each lab … can we mitigate this?</p></li>
<li class="fragment"><p>Reduce, reuse, recycle …</p></li>
</ul>
</section><section id="ants-lineage" class="slide level2">
<h1>ANTs Lineage</h1>
<p><img src="figures/lineage.jpg" /></p>
<p>References: <span class="citation" data-cites="Horn1981">Horn and Schunck (1981)</span>, <span class="citation" data-cites="Gee1993">Gee, Reivich, and Bajcsy (1993)</span>, <span class="citation" data-cites="Grenander1993">Grenander (1993)</span>, <span class="citation" data-cites="Thompson2001">Thompson et al. (2001)</span>, <span class="citation" data-cites="Miller2002">Miller, Trouve, and Younes (2002)</span>, <span class="citation" data-cites="Shen2002">Shen and Davatzikos (2002)</span>, <span class="citation" data-cites="Arnold2014">Arnold (2014)</span>, <span class="citation" data-cites="Thirion1998">Thirion (1998)</span>, <span class="citation" data-cites="Rueckert1999">Rueckert et al. (1999)</span>, <span class="citation" data-cites="Fischl2012">Fischl (2012)</span>, <span class="citation" data-cites="Ashburner2012">Ashburner (2012)</span></p>
</section><section id="diffeomorphisms" class="slide level2">
<h1>Diffeomorphisms</h1>
<div align="center">
<img width="1433" src="./figures/sillyputty.png" frameborder="0"></img>
</div>
<p>plausible physical modeling of large, invertible deformations</p>
<p>“differentiable map with differentiable inverse”</p>
</section><section id="fine-grained-and-flexible-maps" class="slide level2">
<h1>Fine-grained and flexible maps</h1>
<p><img src="figures/highresdiffeos.jpg" /></p>
</section><section id="ants-beyond-registration" class="slide level2">
<h1>ANTs: Beyond Registration</h1>
<p><img src="figures/antscapabilities.jpg" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=atropos+tustison">Atropos</a> segmentation, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=N4+tustison">N4 inhomogeneity correction</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=eigenanatomy+avants">Eigenanatomy</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sparse+canonical+avants">SCCAN</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24852460">Prior-constrained PCA</a>, and <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009425/">atlas-based label fusion</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/21237273">MALF</a> (powerful expert systems for segmentation)</p>
</section><section id="definitions" class="slide level2">
<h1>Definitions</h1>
<ul>
<li class="fragment"><p>Registration <span class="math">\(=\)</span> estimate an “optimal” geometric mapping between image pairs or image sets (e.g. Affine)</p></li>
<li class="fragment"><p>Similarity <span class="math">\(=\)</span> a function relating one image to another, given a transformation (e.g. mutual information)</p></li>
<li class="fragment"><p><span style="color:grey;"> Diffeomorphisms <span class="math">\(=\)</span> differentiable map with differentiable inverse (e.g. “silly putty”, viscous fluid) </span></p></li>
<li class="fragment"><p>Segmentation <span class="math">\(=\)</span> labeling tissue or anatomy in images, usually automated (e.g. K-means)</p></li>
<li class="fragment"><p><span style="color:grey;"> Multivariate <span class="math">\(=\)</span> using many voxels or measurements at once (e.g. PCA, <span class="math">\(p &gt;&gt; n\)</span> ridge regression)</span></p></li>
<li class="fragment"><p>Multiple modality <span class="math">\(=\)</span> using many modalities at once (e.g. DTI and T1 and BOLD)</p></li>
<li class="fragment"><p>MALF: multi-atlas label fusion - using anatomical dictionaries to label new data</p></li>
<li class="fragment"><p>Solutions to challenging statistical image processing problems usually need elements from each of the above</p></li>
</ul>
</section></section>
<section><section id="medical-image-registration-fundamental-tool-for-morphometry-segmentation-motion-estimation-and-data-cleaning" class="titleslide slide level1"><h1><span style="color:red;">Medical Image Registration</span> <br /> Fundamental tool for<br /> morphometry, segmentation,<br /> motion estimation and <br /> <span style="color:blue;">data cleaning</span></h1></section></section>
<section><section id="we-can-compare-apples-and-oranges" class="titleslide slide level1"><h1>we <em>can</em> compare<br /> <span style="color:red;">apples</span> and <span style="color:orange;">oranges</span> …</h1></section><section id="apples-and-oranges" class="slide level2">
<h1>apples and oranges …</h1>
<p><img src="figures/appleorange1.png" /></p>
<p>initialization</p>
</section><section id="apples-and-oranges-1" class="slide level2">
<h1>apples and oranges …</h1>
<p><img src="figures/appleorange2.png" /></p>
<p><span style="color:red;">R</span><span style="color:green;">G</span><span style="color:blue;">B</span> affine</p>
</section><section id="apples-and-oranges-2" class="slide level2">
<h1>apples and oranges …</h1>
<p><img src="figures/appleorange3.png" /></p>
<p><span style="color:red;">R</span><span style="color:green;">G</span><span style="color:blue;">B</span> deformable registration - i.e. registration on color</p>
</section><section id="the-technical-framework" class="slide level2">
<h1>The Technical Framework</h1>
<p><img src="figures/designprinciples.png" /></p>
<p>… and most of it multivariate.</p>
</section><section id="ants-nomenclature-standards" class="slide level2">
<h1>ANTs Nomenclature / Standards</h1>
<p><img src="figures/antsnomen1.jpg" /></p>
</section><section id="ants-nomenclature-standards-1" class="slide level2">
<h1>ANTs Nomenclature / Standards</h1>
<p><img src="figures/antsnomen2.jpg" /></p>
</section><section id="ants-nomenclature-standards-2" class="slide level2">
<h1>ANTs Nomenclature / Standards</h1>
<p><img src="figures/antsnomen3.jpg" /></p>
</section><section id="ants-nomenclature-standards-3" class="slide level2">
<h1>ANTs Nomenclature / Standards</h1>
<p><img src="figures/antsnomen4.jpg" /></p>
</section><section id="the-optimization-problem" class="slide level2">
<h1>The optimization problem</h1>
<p>Find mapping <span class="math">\[ \color{red}{ \phi(x,p) \in \mathcal{T} }\]</span> such that</p>
<p><span class="math">\[ \color{red}{ M(I,J,\phi(x,p)) } \]</span> is minimized</p>
<p>Must select both metric <span class="math">\(\color{red}{M}\)</span> and transformation <span class="math">\(\color{red}{\mathcal{T}}\)</span></p>
<p>… in addition to optimizer and the problem’s resolution</p>
<p>Discussed in more detail <a href="http://www.ncbi.nlm.nih.gov/pubmed/24817849">in this frontiers paper</a></p>
</section><section id="the-a-team-of-similarity-metrics" class="slide level2">
<h1>The <em>A</em>-team of similarity metrics</h1>
<p><img src="figures/towardsstandardmetric.png" /></p>
<p><span class="math">\[ \| I - J \| ~~~~~~~~~~~~~~~~~~~ \frac{&lt; I, J &gt;}{\|I\|\|J\|} ~~~~~~~~~~~~~~~ p(I,J) log \frac{p(I,J)}{p(I)p(J)}\]</span></p>
<p><strong>all metrics</strong> may be computed from <strong>sparse</strong> or <strong>dense</strong> samples and used with low or high-dimensional transformations</p>
<p><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3065962/">our research on similarity metrics for brain registration</a></p>
</section><section id="syn-for-optimization-symmetry" class="slide level2">
<h1><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2276735/">SyN</a> for optimization symmetry</h1>
<p><img src="figures/fishSyN.png" /> Images deform symmetrically along the shape manifold. This eliminates bias in the measurement of image differences.</p>
</section><section id="syn-link-example" class="slide level2">
<h1><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2276735/">SyN (link)</a> Example</h1>
<!-- syn example -->
<div align="center">
<iframe width="1120" height="630" src="http://www.youtube.com/embed/3I9RcRtpOvw" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><a href="http://www.youtube.com/embed/3I9RcRtpOvw">SyN movie</a></p>
</section><section id="concatenated-transformation-metric-stages-are-necessary-in-real-data" class="slide level2">
<h1>Concatenated transformation <span class="math">\(+\)</span> metric stages are necessary in real data</h1>
<ol start="0" type="1">
<li class="fragment"><p>Initialize the mapping ( more on this later )</p></li>
<li class="fragment"><p>Start with a <em>rigid transformation</em>: <span class="math">\(I(x) \approx J(R(x))\)</span> s.t. negative <span class="math">\(MI\)</span> is minimized</p></li>
<li class="fragment"><p>Follow by an <em>affine transformation</em>: <span class="math">\(I(x) \approx J(R(A(x)))\)</span> s.t. negative <span class="math">\(MI\)</span> is minimized with fixed <span class="math">\(R\)</span></p></li>
<li class="fragment"><p>Finally, a <em>diffeomorphism</em>: <span class="math">\(I(x) \approx J(R(A(\phi(x))))\)</span> s.t. <span class="math">\(k\)</span>-neighborhood correlation <span class="math">\(CC_k\)</span> is minimized with fixed <span class="math">\(R, A\)</span></p></li>
<li class="fragment"><p>Output the <em>composite transform</em> <span class="math">\(A \circ R\)</span> as a matrix transformation and <span class="math">\(\phi\)</span> and <span class="math">\(\phi^{-1}\)</span> as deformation fields.</p></li>
</ol>
<p>standard in <a href="http://stnava.github.io/ANTsDoc/">recommended</a> <code>antsRegistration</code> application scripts</p>
</section><section id="minimizing-interpolations" class="slide level2">
<h1>Minimizing interpolations</h1>
<p><img src="figures/oneInterpolation.png" /></p>
<p><span class="math">\(\mathcal{T}_{total} = \mathcal{T}_1 \circ \mathcal{T}_2 \circ \mathcal{T}_3 \circ \mathcal{T}_4\)</span></p>
<p>To avoid compounding interpolation error with the concatenation of transformations, <em>ANTs</em> never uses more than a single interpolation.</p>
<p>We ported many of these ideas into the <a href="http://www.itk.org">Insight ToolKit</a> <br /> as part of its <a href="http://journal.frontiersin.org/Journal/10.3389/fninf.2014.00044/abstract">V4 reboot</a>!</p>
</section><section id="registration-benefits-from-optimal-sampling-strategy" class="slide level2">
<h1>Registration benefits from<br /> <em>optimal sampling strategy</em></h1>
<ul>
<li class="fragment"><p>sampling for <em>both</em> the metric and the transformation</p></li>
<li class="fragment"><p>impacts scalability, memory, optimization accuracy, speed, robustness …</p></li>
<li class="fragment">could be done optimally <em>with massive improvements in performance</em>
<ul>
<li class="fragment">but needs investment in order to achieve “dream” registration scenario</li>
</ul></li>
<li class="fragment"><p>important for new schemes that <em>elect</em> solutions from <strong>anatomical or transformation</strong> dictionaries</p></li>
<li class="fragment"><p>overall, relatively little translational work on this important problem in biomedical imaging</p></li>
</ul>
</section><section id="sampling-feature-selection-multi-start" class="slide level2">
<h1>Sampling &amp; feature selection: Multi-start</h1>
<p><img src="figures/multistart.png" /></p>
<p>Theoretical guarantee of global optimum: improves local optimizers.</p>
<p>Default in <code>antsCorticalThickness</code> pipeline and <code>FSL</code>.</p>
</section><section id="sampling-feature-selection-biomedical-imagery" class="slide level2">
<h1>Sampling &amp; feature selection: Biomedical imagery</h1>
<p><img src="figures/slides1.png" /></p>
<p>Initial configuration of data</p>
</section><section id="sampling-feature-selection-biomedical-imagery-1" class="slide level2">
<h1>Sampling &amp; feature selection: Biomedical imagery</h1>
<p><img src="figures/slides2.png" /></p>
<p>Automatic feature selection</p>
</section><section id="sampling-feature-selection-biomedical-imagery-2" class="slide level2">
<h1>Sampling &amp; feature selection: Biomedical imagery</h1>
<p><img src="figures/slides3.png" /></p>
<p>Resampling allows comparison &amp; slide alignment and <br /> validates the feature selection</p>
<p>Dramatic reduction in computation time / memory requirements</p>
</section><section id="sampling-feature-selection-lesioned-brains" class="slide level2">
<h1>Sampling &amp; feature selection: Lesioned brains</h1>
<p><img src="figures/lesionedbrains.jpg" /></p>
</section><section id="sampling-feature-selection-summary" class="slide level2">
<h1>Sampling &amp; feature selection: Summary</h1>
<ul>
<li class="fragment">we exploit these strategies to:
<ul>
<li class="fragment">accelerate</li>
<li class="fragment">focus</li>
<li class="fragment">validate</li>
</ul></li>
</ul>
</section></section>
<section><section id="differentiable-maps-with-differentiable-inverse-statistics-in-these-spaces" class="titleslide slide level1"><h1>Differentiable maps with<br /> differentiable inverse <br /><span class="math">\(+\)</span> <em>statistics in these spaces</em></h1></section><section id="brain-templates-as-high-dimensional-averages" class="slide level2">
<h1>Brain templates as <em>high-dimensional averages</em></h1>
<p><img src="figures/speciestemplates.png" /></p>
</section><section id="sygn---templates-and-averages-in-deformation-space" class="slide level2">
<h1>SyGN - templates and averages in deformation space</h1>
<p><img src="figures/normvsnorm.png" /> from <a href="http://miykael.github.io/nipype-beginner-s-guide/ANTS.html">miykael</a></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/15501083">geodesic image averages</a></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/19818860">optimal templates 2</a></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/23284904">canine template</a></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/23516289">chimpanzees</a></p>
</section><section id="statistics-in-deformation-space" class="slide level2">
<h1>Statistics in deformation space</h1>
<p><a href="http://www.youtube.com/embed/8GgHG-rApiE">AIBS movie</a></p>
</section><section id="average-republican-and-democratic-congressmen" class="slide level2">
<h1>Average Republican and Democratic congressmen</h1>
<div align="center">
<img src="figures/democrat_left_repub_right.png" frameborder="0"></img>
</div>
<p><a href="http://ntustison.github.io/CongressionalFaceTemplates/">congress</a></p>
</section><section id="we-build-templates-to-store-and-transfer-prior-knowledge" class="slide level2">
<h1>We build templates to <em>store</em> and <em>transfer</em> prior knowledge</h1>
</section></section>
<section><section id="tissue-segmentation" class="titleslide slide level1"><h1>Tissue segmentation</h1></section><section id="segmentation-framework" class="slide level2">
<h1>Segmentation Framework</h1>
<ol type="1">
<li class="fragment"><p>Bias correction (with optional priors)</p></li>
<li class="fragment"><p>Prior-based tissue segmentation</p></li>
<li class="fragment"><p>Prior-based anatomical labeling</p></li>
<li class="fragment"><p>Iteration through above steps (optional)</p></li>
</ol>
</section><section id="we-tried-n3-and-fsl-fast-for-these-problems-and-dislike-matlab" class="slide level2">
<h1>We tried N3 and FSL-FAST for these problems … and <em>dislike</em> Matlab …</h1>
<p>failed to locate well-implemented open-source resources for general purpose prior-based segmentation and inhomogeneity correction …</p>
</section><section id="atropos-bayesian-n-class-multivariate-segmentation" class="slide level2">
<h1>Atropos: Bayesian <span class="math">\(N\)</span>-class multivariate segmentation</h1>
<ul>
<li class="fragment"><p>Similar to our experience with N3, we tried to incorporate FAST (from the FMRIB at Oxford) into an <em>ANTs</em> processing pipeline.</p></li>
<li class="fragment"><p>We failed to successfully incorporate priors into FAST.</p></li>
<li class="fragment"><p>Related, BA went to a segmentation-related worksop at MICCAI and aired disappointment that so much of what had been developed in the community over the last 20+ years has not been made publicly available. “What’s wrong with you people!”</p></li>
<li class="fragment"><p>3-tissue algorithm in ImageMath <span class="math">\(\rightarrow\)</span> multivariate, n-class Atropos</p></li>
</ul>
</section><section id="atropos-components" class="slide level2">
<h1>Atropos components</h1>
<div align="center">
<img height="350" src="./figures/atropos2.png" frameborder="0"></img>
</div>
</section><section id="babies" class="slide level2">
<h1>Babies</h1>
<p><img src="figures/baby.png" /></p>
</section></section>
<section><section id="can-we-accurately-measure-cortical-thickness-by-directly-using-the-image-space" class="titleslide slide level1"><h1>Can we accurately measure cortical thickness by DiReCTly using the image space?</h1></section><section id="kellyslater-rightarrow-kellykapowski" class="slide level2">
<h1>KellySlater <span class="math">\(\rightarrow\)</span> KellyKapowski</h1>
<p><img src="figures/kkks.png" alt="KK-KS" /></p>
<p>Several years of development by SR Das, BA, NT (KK fan)</p>
</section><section id="atropos-kk-example" class="slide level2">
<h1>Atropos <span class="math">\(+\)</span> KK Example</h1>
<p><img src="figures/atropos.png" /></p>
</section></section>
<section><section id="bias-correction-a.k.a.-inhomogeneity-correction" class="titleslide slide level1"><h1>Bias Correction a.k.a. Inhomogeneity Correction</h1></section><section id="n4" class="slide level2">
<h1>N4</h1>
<ul>
<li class="fragment"><p>N3 (developed at the Montreal Neurological Institute) has been the gold standard for bias correction—used in important projects such as ADNI</p></li>
<li class="fragment"><p>N3 is a set of perl scripts that works natively with the MINC file format which we tried to incorporate into an <em>ANTs</em> processing pipeline.</p></li>
<li class="fragment"><p>We had so much trouble converting back and forth between ITK-compatible Nifti format and MINC that BA suggested we try to implement N3 in ITK.</p></li>
<li class="fragment"><p>NT had some experience with B-splines and added some other tweaks giving birth to N4.</p></li>
</ul>
</section><section id="n4-introduction" class="slide level2">
<h1>N4 Introduction</h1>
<p><img src="figures/n4_introduction.png" /></p>
</section><section id="nonparametric-nonuniform-intensity-normalization-n3" class="slide level2">
<h1>Nonparametric nonuniform intensity normalization (N3)</h1>
<p>Sled et al., “A nonparametric method for automatic correction of intensity nonuniformity in MRI Data,” <em>IEEE-TMI</em>, 17(1), 1998.</p>
</section><section class="slide level2">

<p>Boyes et al., “Intensity non-uniformity correction using N3 on 3-T scanners with multichannel phased array coils,” <em>NeuroImage</em>, 39(4), 2008.</p>
<blockquote>
<p>In a comparison of several correction techniques N3 performed well (Arnold et al., 2001). Also, the algorithm and software are in the public domain (<a href="http://www.bic.mni.mcgill.ca/software/N3/" class="uri">http://www.bic.mni.mcgill.ca/software/N3/</a>) and is probably the most widely used non-uniformity correction technique in neurological imaging.</p>
</blockquote>
<p>Zheng et al., “Improvement of brain segmentation accuracy by optimizing non-uniformity correction using N3,” <em>NeuroImage</em>, 48(1), 2009.</p>
<blockquote>
<p>Among existing approaches, the nonparametric non-uniformity intensity normalization method N3 (Sled et al., 1998) is one of the most frequently used… High performance and robustness have practically turned N3 into an industry standard.</p>
</blockquote>
<p>Vovk et al., “A Review of Methods for Correction of Intensity Inhomogeneity in MRI,” <em>IEEE-TMI</em>, 26(3), 2007.</p>
<blockquote>
<p>A well-known intensity inhomogeneity correction method, known as the N3 (nonparametric nonuniformity normalization), was proposed in [15]… Interestingly, no improvements have been suggested for this highly popular and successful method… The nonparametric nonuniformity normalization (N3) method [15] has obviously become the standard method against which other methods are compared.</p>
</blockquote>
</section><section id="code" class="slide level2">
<h1>Code</h1>
<pre><code>COMMAND:
     N4BiasFieldCorrection

OPTIONS:
     -d, --image-dimensionality 2/3/4
     -i, --input-image inputImageFilename
     -x, --mask-image maskImageFilename
     -w, --weight-image weightImageFilename
     -s, --shrink-factor 1/2/3/4/...
     -c, --convergence [&lt;numberOfIterations=50x50x50x50&gt;,&lt;convergenceThreshold=0.0&gt;]
     -b, --bspline-fitting [splineDistance,&lt;splineOrder=3&gt;]
                           [initialMeshResolution,&lt;splineOrder=3&gt;]
     -t, --histogram-sharpening [&lt;FWHM=0.15&gt;,&lt;wienerNoise=0.01&gt;,&lt;numberOfHistogramBins=200&gt;]
     -o, --output correctedImage
                  [correctedImage,&lt;biasField&gt;]
     -h
     --help</code></pre>
<blockquote>
<p>Talk is cheap, show me the code.</p>
</blockquote>
</section></section>
<section><section id="learning-from-anatomical-dictionaries" class="titleslide slide level1"><h1>Learning from anatomical dictionaries</h1></section><section id="joint-label-fusion" class="slide level2">
<h1>Joint Label Fusion</h1>
<p>FIXME</p>
<p>Use dictionaries to labels</p>
</section></section>
<section><section id="evaluation-results" class="titleslide slide level1"><h1>Evaluation results</h1></section><section id="section-1" class="slide level2">
<h1></h1>
<p><img src="figures/evalhistory.png" /></p>
</section><section id="anatomical-dictionaries" class="slide level2">
<h1>Anatomical dictionaries</h1>
<p><img src="figures/sata2013.png" /></p>
<p>we provided the <em>standard</em> registration results for <span class="math">\(&gt;\)</span> 20,000 image pairs at <a href="https://masi.vuse.vanderbilt.edu/workshop2013/index.php/MICCAI_2013_SATA_Challenge_and_Workshop:Current_events">SATA 2013</a></p>
</section><section id="label-fusion-link" class="slide level2">
<h1><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3049832/">label fusion (link)</a></h1>
<p><img src="figures/sata2013.jpg" /></p>
</section><section id="multiple-metrics-improve-performance" class="slide level2">
<h1>Multiple metrics improve performance</h1>
<p><img src="figures/multivariateSATA.jpg" /></p>
<p>to our knowledge, ANTs is the only freely available system that can solve this problem in a fully multivariate manner.</p>
<p>Hongzhi Wang won the “walk in the park” award for this work …</p>
</section></section>
<section><section id="ants-versus-freesurfer-quantifying-life-span-brain-health" class="titleslide slide level1"><h1>ANTs versus Freesurfer:<br /> Quantifying <em>life span</em> brain health</h1></section><section id="big-data-problem-from-public-resources" class="slide level2">
<h1>“Big data” problem from public resources</h1>
<p><img src="figures/lifebrains.jpg" /></p>
<p>TOT, NKI, IXI, Oasis, ADNI … several thousand images</p>
</section><section id="ants-versus-freesurfer-quantifying-life-span-brain-health-1" class="slide level2">
<h1>ANTs versus Freesurfer:<br /> Quantifying <em>life span</em> brain health</h1>
<ul>
<li class="fragment"><p>Freesurfer is the historical standard for measuring cortical thickness</p></li>
<li class="fragment"><p>instead of using surfaces to measure cortical thickness, we use the image space <em>DiReCTly</em></p></li>
<li class="fragment"><p><a href="http://stnava.github.io/ANTsTalk/#/putting-it-all-together-can-we-quantify-life-span-brain-health-in-individuals-and-in-populations">see this section of a different talk</a></p></li>
<li class="fragment"><p>and this “big data” paper: <a href="http://www.ncbi.nlm.nih.gov/pubmed/24879923">Large-scale evaluation of ANTs and FreeSurfer cortical thickness measurements</a></p></li>
<li class="fragment"><p>comparison of prediction from automated cortical thickness measurement from 4 public datasets</p></li>
<li class="fragment"><p><span class="math">\(&gt;\)</span> 1200 subjects, age 7 to over 90 years old</p></li>
<li class="fragment"><p><em>hint</em>: ANTs thickness measurements have higher prediction accuracy relative to Freesurfer ( implying we extract more information from the data )</p></li>
<li class="fragment"><p>ANTs methods consistently improve statistical power <a href="http://www.ncbi.nlm.nih.gov/pubmed/24687814">eigenanatomy</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=syn+epstein+avants">syn</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24817849">itkv4</a> … also, see <a href="http://www.ncbi.nlm.nih.gov/pubmed/24650605">Schwarz CG, et al.</a> re: TBSS and related work in fMRI <a href="http://www.ncbi.nlm.nih.gov/pubmed/15980148">Miller, PNAS</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24167043">Azab, et al in Hippocampus</a>.</p></li>
</ul>
</section><section id="ants-vs-freesurfer" class="slide level2">
<h1>ANTS vs Freesurfer</h1>
<div align="center">
<img height="350" src="./figures/evaluation.png" frameborder="0"></img>
</div>
</section><section id="ants-vs-freesurfer-2" class="slide level2">
<h1><em>ANTs</em> vs Freesurfer 2</h1>
<p><img src="figures/antsvfreesurfer2.png" /></p>
</section><section id="ants-malf-labeling" class="slide level2">
<h1><em>ANTs</em> MALF Labeling</h1>
<p><img src="figures/antsatroposn4malf.png" /></p>
</section><section id="the-ants-structural-brain-mapping-pipeline" class="slide level2">
<h1>The <em>ANTs</em> structural brain mapping pipeline</h1>
<p><img src="figures/pipeline.png" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/24879923"><em>Large-scale evaluation of </em>ANTs* and FreeSurfer cortical thickness measurements<em>, NeuroImage 2014.</em></a></p>
<p>All software components are open source and part of the Advanced Normalization Tools (ANTs) repository.</p>
</section><section id="basic-components-of-the-pipeline" class="slide level2">
<h1>Basic components of the pipeline</h1>
<div align="center">
<img height="350" src="./figures/components.png" frameborder="0"></img>
</div>
<ol type="1">
<li class="fragment">template building (offline)</li>
<li class="fragment">brain extraction</li>
<li class="fragment">cortical thickness estimation</li>
<li class="fragment">cortical parcellation</li>
</ol>
</section><section id="template-building" class="slide level2">
<h1>Template building</h1>
<p><em>Tailor data to your specific cohort</em></p>
<div align="center">
<img height="350" src="./figures/templates.png" frameborder="0"></img>
</div>
<ul>
<li class="fragment">Templates representing the average mean shape and intensity are built directly from the cohort to be analyzed, e.g. pediatric vs. middle-aged brains.</li>
<li class="fragment">Acquisition and anonymization (e.g. defacing) protocols are often different.</li>
</ul>
</section><section id="template-building-cont." class="slide level2">
<h1>Template building (cont.)</h1>
<div align="center">
<img height="350" src="./figures/templatePriors.png" frameborder="0"></img>
</div>
<p>Each template is <a href="https://github.com/ntustison/antsCookTemplatePriorsExample">processed</a> to produce auxiliary images which are used for brain extraction and brain segmentation.</p>
</section><section id="brain-extraction" class="slide level2">
<h1>Brain extraction</h1>
<div align="center">
<img height="380" src="./figures/brainExtraction.png" frameborder="0"></img>
</div>
<p>Comparison with de facto standard FreeSurfer package. Note the difference in separation of the gray matter from the surrounding CSF. (0 failures out of 1205 scans)</p>
</section><section id="brain-segmentation" class="slide level2">
<h1>Brain segmentation</h1>
<div align="center">
<img height="350" src="./figures/brainSegmentation.png" frameborder="0"></img>
</div>
<p>Randomly selected healthy individuals. Atropos gets good performance across ages.</p>
</section><section id="cortical-thickness-estimation" class="slide level2">
<h1>Cortical thickness estimation</h1>
<div align="center">
<img height="250" src="./figures/corticalThicknessEstimation.png" frameborder="0"></img>
</div>
<p>In contrast to FreeSurfer which warps coupled surface meshes to segment the gray matter, <em>ANTs</em> diffeomorphically registers the white matter to the combined gray/white matters while simultaneously estimating thickness.</p>
</section></section>
<section><section id="registration-statistics-frontiers-and-innovation" class="titleslide slide level1"><h1>Registration &amp; statistics:<br /> Frontiers and innovation</h1></section><section id="multivariate-statistical-fields-arise-from-fused-modalities" class="slide level2">
<h1>multivariate statistical fields arise from fused modalities</h1>
<p><img src="figures/statisticalfields.png" alt="images at measurement fields" /></p>
<p><em>Many opportunities for statistical advancements</em></p>
</section><section id="scientific-data-2014" class="slide level2">
<h1>Scientific Data 2014</h1>
<p><img src="figures/ptbp2.png" /></p>
</section><section id="network-of-predictors-for-age" class="slide level2">
<h1>“Network” of predictors for age</h1>
<p>…</p>
</section><section id="itkantsr-antsr" class="slide level2">
<h1>ITK+ANTs+R = <span style="color:red;"><em>ANTsR</em></span></h1>
</section><section id="agnostic-statistics" class="slide level2">
<h1>Agnostic statistics</h1>
<p><img src="figures/antsrex.jpg" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3961542/">McMillan et al.</a></p>
</section><section id="a-quick-antsr-example" class="slide level2">
<h1>A Quick <span style="color:grey;"><em>ANTsR</em></span> example</h1>
<p>This is an executable <em>ANTsR</em> code block - <em>N</em>-dimensional statistics to go with our <em>N</em>-dimensional image processing software!</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ANTsR)
dim&lt;-<span class="dv">2</span>
filename&lt;-<span class="kw">getANTsRData</span>(<span class="st">&#39;r16&#39;</span>)
img&lt;-<span class="kw">antsImageRead</span>( filename , dim )
filename&lt;-<span class="kw">getANTsRData</span>(<span class="st">&#39;r64&#39;</span>)
img2&lt;-<span class="kw">antsImageRead</span>( filename , dim )
mask&lt;-<span class="kw">getMask</span>(img,<span class="dv">50</span>,<span class="kw">max</span>(img),T)
mask2&lt;-<span class="kw">getMask</span>(img,<span class="dv">150</span>,<span class="kw">max</span>(img),T)
nvox&lt;-<span class="kw">sum</span>( mask ==<span class="st"> </span><span class="dv">1</span> )
nvox2&lt;-<span class="kw">sum</span>( mask2 ==<span class="st"> </span><span class="dv">1</span> )</code></pre>
<p>The brain has 17395 voxels …</p>
</section><section id="a-quick-antsr-example-1" class="slide level2">
<h1>A Quick <span style="color:grey;"><em>ANTsR</em></span> example</h1>
<p>Simulate a population morphometry study - a “VBM” …</p>
<pre class="sourceCode r"><code class="sourceCode r">simnum&lt;-<span class="dv">10</span>
imglist&lt;-<span class="kw">list</span>()
imglist2&lt;-<span class="kw">list</span>()
for ( i in <span class="dv">1</span>:simnum ) {
  img1sim&lt;-<span class="kw">antsImageClone</span>(img)
  img1sim[ mask==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox,<span class="dt">mean=</span><span class="fl">0.5</span>)
  img1sim[ mask2==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox2,<span class="dt">mean=</span><span class="fl">2.0</span>)
  img2sim&lt;-<span class="kw">antsImageClone</span>(img2)
  img2sim[ mask==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox,<span class="dt">mean=</span><span class="fl">0.20</span>)
  imglist&lt;-<span class="kw">lappend</span>(imglist,img1sim)
  imglist2&lt;-<span class="kw">lappend</span>(imglist2,img2sim)
}
imglist&lt;-<span class="kw">lappend</span>( imglist, imglist2 )
mat&lt;-<span class="kw">imageListToMatrix</span>( imglist, mask )
DX&lt;-<span class="kw">factor</span>( <span class="kw">c</span>( <span class="kw">rep</span>(<span class="dv">0</span>,simnum), <span class="kw">rep</span>(<span class="dv">1</span>,simnum) ) )
mylmresults&lt;-<span class="kw">bigLMStats</span>( <span class="kw">lm</span>( mat ~<span class="st"> </span>DX ) )
qvals&lt;-<span class="kw">p.adjust</span>( mylmresults$pval.model ) </code></pre>
<p>The minimum q-value is 2.5212 × 10<sup>-6</sup> …</p>
</section><section id="visualize-the-histograms-of-effects" class="slide level2">
<h1>Visualize the histograms of effects</h1>
<pre class="sourceCode r"><code class="sourceCode r">whichvox&lt;-qvals &lt;<span class="st"> </span><span class="fl">1.e-2</span>
voxdf&lt;-<span class="kw">data.frame</span>( <span class="dt">volume=</span><span class="kw">c</span>( <span class="kw">as.numeric</span>( mat[,whichvox] ) ), <span class="dt">DX=</span>DX )
<span class="kw">ggplot</span>(voxdf, <span class="kw">aes</span>(volume, <span class="dt">fill =</span> DX)) +<span class="st"> </span><span class="kw">geom_density</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>)</code></pre>
<p><img src="FigsAntsHistory/vizmorph.png" title="plot of chunk vizmorph" alt="plot of chunk vizmorph" width="864" /></p>
</section><section id="visualize-the-anatomical-distribution" class="slide level2">
<h1>Visualize the anatomical distribution</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotANTsImage</span>(img,<span class="dt">functional=</span><span class="kw">list</span>(betas),<span class="dt">threshold=</span>thresh,
  <span class="dt">outname=</span>ofn)</code></pre>
<p><img src="FigsAntsHistory/vizmorph2.jpg" /></p>
</section><section id="network-visualization" class="slide level2">
<h1>Network visualization</h1>
<p>see <code>?plotBasicNetwork</code></p>
<p><img src="FigsAntsHistory/network.png" /></p>
</section><section id="the-power-of-ants-r-rightarrow-reproducible-imaging-science" class="slide level2">
<h1>The power of <em>ANTs</em> <span class="math">\(+\)</span> <em>R</em> <span class="math">\(\rightarrow\)</span><br /> <span style="color:red;"><strong>Reproducible imaging science</strong></span></h1>
<p><img src="figures/antsgoals.png" /></p>
<p>… used in <a href="http://www.ncbi.nlm.nih.gov/pubmed/24096125">“Sparse canonical correlation analysis relates network-level atrophy to multivariate cognitive measures in a neurodegenerative population”</a> and several upcoming …</p>
</section></section>
<section><section id="wrap-up-discussion" class="titleslide slide level1"><h1>Wrap-up &amp; Discussion</h1></section><section id="many-instructional-examples-for-new-colleagues" class="slide level2">
<h1>Many instructional examples for new colleagues</h1>
<p><a href="http://stnava.github.io/ANTs/">see examples @ <em>ANTs</em> webpage</a></p>
</section><section id="recap" class="slide level2">
<h1>Recap</h1>
<ul>
<li class="fragment"><p>Powerful, general-purpose, <span style="color:red;">well-evaluated</span> registration and segmentation.</p></li>
<li class="fragment"><p>Differentiable maps with differentiable inverse <span style="color:red;"><span class="math">\(+\)</span> statistics in these spaces</span></p></li>
<li class="fragment"><p>Evaluated in multiple problem domains</span> via internal studies &amp; open competition</p></li>
<li class="fragment"><p>Borg philosophy: <span style="color:red;">“best of”</span> from I/O, to processing to statistical methods</p></li>
<li class="fragment"><p>Open source, testing, many examples, consistent style, multiple platforms, active community support …</p></li>
<li class="fragment"><p>Integration with <em>R</em> <span class="math">\(+\)</span> novel tools for prediction, decoding, high-to-low dimensional statistics.</p></li>
<li class="fragment"><p>Collaborations with <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p></li>
</ul>
</section><section id="challenges-computational-and-scientific" class="slide level2">
<h1>Challenges: Computational and Scientific</h1>
<ul>
<li class="fragment">Scalability
<ul>
<li class="fragment"><strong>need to fuse feature selection methods with transformation optimization</strong></li>
<li class="fragment"><strong>need to leverage existing ITK streaming infrastructure in application level tool</strong></li>
</ul></li>
<li class="fragment">Domain expertise: Customizable for specific problems but sometimes not specific enough</li>
<li class="fragment">“Plausible physical modeling …” - this should vary per problem … but doesn’t.
<ul>
<li class="fragment">a fabulous project would be to resolve this issue at a large-scale e.g. for reconstructing neurons, measuring white matter elaboration …</li>
<li class="fragment">our prior FEM work is one potential solution</li>
</ul></li>
<li class="fragment">Rapid development: colleagues still need familiarity with compilation for latest ANTs features</li>
<li class="fragment">Latest theoretical advances in registration not yet wrapped for users</li>
<li class="fragment">Need more <a href="http://stnava.github.io/ANTs/">Documentation</a> &amp; <a href="http://testing.psychiatry.uiowa.edu/CDash/index.php?project=ANTS">testing</a> …</li>
</ul>
</section><section id="tools-you-can-use-for-imaging-science" class="slide level2">
<h1>Tools you can use for imaging science</h1>
<ul>
<li class="fragment"><p>Core developers: <em>B. Avants, N. Tustison, H. J. Johnson, J. T. Duda</em></p></li>
<li class="fragment"><p>Many contributors, including users …</p></li>
<li class="fragment"><p>Multi-platform, multi-threaded C++ <a href="stnava.github.io/ANTs" class="uri">stnava.github.io/ANTs</a></p></li>
<li class="fragment"><p>Developed in conjunction with <a href="http://www.itk.org/"><a href="http://www.itk.org/" class="uri">http://www.itk.org/</a></a></p></li>
<li class="fragment"><p>R wrapping and extension <a href="stnava.github.io/ANTsR" class="uri">stnava.github.io/ANTsR</a></p></li>
<li class="fragment"><p>rapid development, regular testing <span class="math">\(+\)</span> many eyes <span class="math">\(\rightarrow\)</span> bugs are shallow</p></li>
</ul>
<p><img style="float: right" src="figures/penn.png" /> <img style="float: left" src="figures/picsl.jpg" /></p>
</section></section>
<section><section id="analysis-philosophy-and-published-opinions" class="titleslide slide level1"><h1>Analysis philosophy and <br /> published opinions</h1></section><section id="what-is-and-is-not-image-registration" class="slide level2">
<h1>What is and <em>is not</em><br /> image registration</h1>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/23116330"><em>not</em> registration</a></p>
</section><section id="voodoo-in-voxel-based-analysis" class="slide level2">
<h1>Voodoo in voxel-based analysis</h1>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=logical+circularity+tustison">logical circularity VBA</a></p>
</section><section id="instrumentation-bias-in-the-use-and-evaluation-of-software" class="slide level2">
<h1>Instrumentation bias in the use and evaluation of software</h1>
<p><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3766821/?report=reader">Instrumentation bias in the use and evaluation of software</a></p>
</section></section>
<section><section id="references" class="titleslide slide level1 unnumbered"><h1>References</h1></section></section>
    </div>
  </div>

  <script src="index_files/reveal.js-2.6.1/lib/js/head.min.js"></script>
  <script src="index_files/reveal.js-2.6.1/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'fade',

        // Optional libraries used to extend on reveal.js
        dependencies: []});
    </script>

  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

  </body>
</html>
